# Generative Adversarial Networks (GAN) with Mechanical MNIST (Cahn-Hilliard) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/sedaoturak/dcgan_cahn-hilliard/blob/main/DCGAN_Cahn_Hillard.ipynb)

Generative model Deep Convolutional Generative Adversarial Networks (DCGAN) implementation for the predictions of phase separation in binary alloys

## Goal
This repository consists of a notebook for the implementation of one of the common generative model architectures: Generative Adversarial Networks (GAN) in material science domain. GANs, similar to VAEs, represent each datapoint as probability distribution and embeds the meaningful relations between the datapoints in the low-dimensional latent space. These models can be used to perform inverse materials design, which enables to predict the structure or the processing parameters for given target material properties.

This example was created after VAE implementation of the same problem before -which can found in [this](https://github.com/sedaoturak/vae_cahn-hilliard/) repository, by using the [Mechanical MNIST (Cahn-Hilliard) Dataset](https://github.com/elejeune11/Mechanical-MNIST-Cahn-Hilliard).
This dataset consists of 2D microstructures generated by Cahn-Hilliard (CH) equation and their strain energy obtained from finite element simulations. The detailed information about the dataset and Cahn-Hilliard structure can be found in the [VAE implementation](https://github.com/sedaoturak/vae_cahn-hilliard/) of the problem.
<p align="center">
  <img src="https://github.com/sedaoturak/vae_cahn-hilliard/blob/main/mixing.png?raw=true" width=60% height=60%>

image credit: [paper](https://www.nature.com/articles/s41578-019-0121-4)
## Methodology
When the model is trained with the dataset consisting of microstructure images of the material, The generator part of the model will be used to design Cahn-Hilliard structures with desired strain energy or strength.

The improvements listed below were done in training the DCGAN model compared to [VAE implementation](https://github.com/sedaoturak/vae_cahn-hilliard) because Discriminator learned the images very fast, and consequently Generator couldn't find time to learn to generate images and trained poorly. To balance the competition between Discriminator and Generator:
1. The learning rate was lowered for Discriminator.
2. Generator was trained 4 times more per batch than Discriminator.
3. Label smoothing was applied for real images for Discriminator to take more time to learn.
4. Instance noise was added to fake images to make learning task harder for Discriminator.
5. Dropout was applied in both networks to prevent overfitting.

## Works to do
Condition will be added to the model so that microstructures can be designed by a given strength.

## Additional Notes
The code was written on Google Colab platform. Different installation of libraries or functions might be required to use the notebook in local machines.
The code for the GAN model and its training were taken from [this](https://github.com/Yuumna/GAN-PyTorch) repository (special thanks!).
